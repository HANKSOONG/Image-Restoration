{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**For this demo, you only need to run the first part, enter the image address and the image address you want to output in the second part and click Run.**"
      ],
      "metadata": {
        "id": "e0PSiaTIAgOn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part:1 Function define"
      ],
      "metadata": {
        "id": "E_tbBceoA3zB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SAU-ywaG7PJJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download weight of model\n",
        "!pip install gdown\n",
        "!gdown https://drive.google.com/uc?id=1kX9MaNp3m8B5XAwCfqo9yrXwHhyAEpwP"
      ],
      "metadata": {
        "id": "SJXXCLS0_ZAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# —— DnCNN_SR Definition ——\n",
        "class DnCNN_SR(nn.Module):\n",
        "    def __init__(self, scale=2, in_channels=3, features=64, num_layers=17):\n",
        "        super().__init__()\n",
        "        layers = [nn.Conv2d(in_channels, features, 3, 1, 1),\n",
        "                  nn.ReLU(inplace=True)]\n",
        "        for _ in range(num_layers-2):\n",
        "            layers += [\n",
        "                nn.Conv2d(features, features, 3,1,1),\n",
        "                nn.BatchNorm2d(features),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ]\n",
        "        layers += [nn.Conv2d(features, in_channels*(scale**2), 3,1,1)]\n",
        "        self.body = nn.Sequential(*layers)\n",
        "        self.upsample = nn.PixelShuffle(scale)\n",
        "        self.scale = scale\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Bilinear upsampling for the residual branch\n",
        "        up = F.interpolate(x, scale_factor=self.scale,\n",
        "                           mode='bilinear', align_corners=False)\n",
        "        # Model branch restores details\n",
        "        res = self.body(x)\n",
        "        res = self.upsample(res)\n",
        "        return up + res\n",
        "\n",
        "# —— Inverse Normalization ——\n",
        "inv_norm = transforms.Normalize(\n",
        "    mean=[-m/s for m,s in zip([0.485,0.456,0.406],[0.229,0.224,0.225])],\n",
        "    std =[1/s    for s    in            [0.229,0.224,0.225]]\n",
        ")\n",
        "\n",
        "def denorm(tensor):\n",
        "    return torch.clamp(inv_norm(tensor), 0.0, 1.0)"
      ],
      "metadata": {
        "id": "eHgq-lq07Siw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process the image\n",
        "def process_image(input_path, weights_path, output_path):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # 1. Load model\n",
        "    model = DnCNN_SR(scale=2, in_channels=3, features=64, num_layers=17)\n",
        "    model.load_state_dict(torch.load(weights_path, map_location=device))\n",
        "    model.to(device).eval()\n",
        "\n",
        "    # 2. Read and preprocess: no resizing, retain original size\n",
        "    img = Image.open(input_path).convert(\"RGB\")\n",
        "    tf = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                             std =[0.229,0.224,0.225])\n",
        "    ])\n",
        "    inp = tf(img).unsqueeze(0).to(device)  # [1,3,H,W]\n",
        "\n",
        "    # 3. Forward inference\n",
        "    with torch.no_grad():\n",
        "        out = model(inp)                   # [1,3,2H,2W]\n",
        "        out = denorm(out.squeeze(0).cpu()) # Denormalize and remove batch dimension\n",
        "\n",
        "    # 4. Save result\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    save_image(out, output_path)\n",
        "\n",
        "    print(f\"Restored image saved to {output_path}\")"
      ],
      "metadata": {
        "id": "_mXTgffG8pjz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Only need to copy image path and write down output path here"
      ],
      "metadata": {
        "id": "D70d5aQs_wPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process_image(\"path/to/input_image.png\", \"/content/best_dncnn_sr.pth\", \"path/to/output_image.png\")"
      ],
      "metadata": {
        "id": "N_xvkABf93Yf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}