{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EIOMn1_Go9nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/realblur+gopro.zip\" -d \"/content/datasets\""
      ],
      "metadata": {
        "id": "Nbghz20UpAxl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torchvision.models import vgg16\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "!pip install pytorch-msssim\n",
        "from pytorch_msssim import ssim\n",
        "!pip install lpips\n",
        "import lpips\n",
        "import math"
      ],
      "metadata": {
        "id": "bwjFUvocAupX",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_count = os.cpu_count()\n",
        "\n",
        "print(f\"Number of CPU cores: {cpu_count}\")"
      ],
      "metadata": {
        "id": "QJA3cX8hqjFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "train_blur_dir = \"/content/datasets/content/datasets/train/blur_gamma\"\n",
        "train_sharp_dir= \"/content/datasets/content/datasets/train/sharp\"\n",
        "val_blur_dir   = \"/content/datasets/content/datasets/val/blur_gamma\"\n",
        "val_sharp_dir  = \"/content/datasets/content/datasets/val/sharp\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# function of denorm\n",
        "inv_norm = transforms.Normalize(\n",
        "    mean=[-m/s for m,s in zip([0.485,0.456,0.406],[0.229,0.224,0.225])],\n",
        "    std =[1/s    for s in            [0.229,0.224,0.225]],\n",
        ")\n",
        "def denorm(x):\n",
        "    return torch.clamp(inv_norm(x), 0.0, 1.0)\n",
        "\n",
        "# Dataset for true SR+Enhancement task\n",
        "class SRDataset(Dataset):\n",
        "    def __init__(self, blur_dir, sharp_dir, transform):\n",
        "        self.lr_paths = sorted(os.path.join(blur_dir, f)\n",
        "                               for f in os.listdir(blur_dir)\n",
        "                               if f.endswith('.png'))\n",
        "        self.hr_paths = sorted(os.path.join(sharp_dir, f)\n",
        "                               for f in os.listdir(sharp_dir)\n",
        "                               if f.endswith('.png'))\n",
        "        self.transform = transform\n",
        "    def __len__(self):\n",
        "        return min(len(self.lr_paths), len(self.hr_paths))\n",
        "    def __getitem__(self, idx):\n",
        "        lr = Image.open(self.lr_paths[idx]).convert(\"RGB\").resize((640,360), Image.BILINEAR)\n",
        "        hr = Image.open(self.hr_paths[idx]).convert(\"RGB\").resize((1280,720), Image.BILINEAR)\n",
        "        if self.transform:\n",
        "            lr = self.transform(lr)\n",
        "            hr = self.transform(hr)\n",
        "        return lr, hr\n",
        "\n",
        "# Multi-scale Patch Dataset for Training\n",
        "class MultiScalePatchDataset(Dataset):\n",
        "    def __init__(self, base_ds, patch_sizes=[128,256], out_size=256):\n",
        "        self.ds = base_ds\n",
        "        self.patch_sizes = patch_sizes\n",
        "        self.out_size = out_size\n",
        "        self.scale = 2\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "    def __getitem__(self, idx):\n",
        "        lr, hr = self.ds[idx]\n",
        "        _, H, W = lr.shape\n",
        "        ps = random.choice(self.patch_sizes)\n",
        "        top  = random.randint(0, H-ps)\n",
        "        left = random.randint(0, W-ps)\n",
        "        lr_p = lr[:, top:top+ps, left:left+ps]\n",
        "        hr_p = hr[:, top*self.scale:top*self.scale+ps*self.scale,\n",
        "                  left*self.scale:left*self.scale+ps*self.scale]\n",
        "        # resize to fixed\n",
        "        lr_p = F.interpolate(lr_p.unsqueeze(0),\n",
        "                             size=(self.out_size, self.out_size),\n",
        "                             mode='bilinear', align_corners=False).squeeze(0)\n",
        "        hr_p = F.interpolate(hr_p.unsqueeze(0),\n",
        "                             size=(self.out_size*self.scale,\n",
        "                                   self.out_size*self.scale),\n",
        "                             mode='bilinear', align_corners=False).squeeze(0)\n",
        "        return lr_p, hr_p\n",
        "\n",
        "# Center Patch Dataset for Validation\n",
        "class CenterPatchDataset(Dataset):\n",
        "    def __init__(self, base_ds, patch_size=256):\n",
        "        self.ds = base_ds\n",
        "        self.ps = patch_size\n",
        "        self.scale = 2\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "    def __getitem__(self, idx):\n",
        "        lr, hr = self.ds[idx]\n",
        "        _, H, W = lr.shape\n",
        "        top  = (H - self.ps)//2\n",
        "        left = (W - self.ps)//2\n",
        "        lr_p = lr[:, top:top+self.ps, left:left+self.ps]\n",
        "        hr_p = hr[:, top*self.scale:top*self.scale+self.ps*self.scale,\n",
        "                  left*self.scale:left*self.scale+self.ps*self.scale]\n",
        "        return lr_p, hr_p\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "i5S4X-8ILNCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Definition\n",
        "class SimpleNAFBlock(nn.Module):\n",
        "    def __init__(self, c):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(c,c,3,1,1)\n",
        "        self.relu  = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(c,c,3,1,1)\n",
        "    def forward(self, x):\n",
        "        return x + self.conv2(self.relu(self.conv1(x)))\n",
        "\n",
        "class NAFNet(nn.Module):\n",
        "    def __init__(self, in_c=3, width=128, n_blocks=20, scale=2):\n",
        "        super().__init__()\n",
        "        self.scale = scale\n",
        "        self.entry = nn.Conv2d(in_c, width, 3,1,1)\n",
        "        self.body  = nn.Sequential(*[SimpleNAFBlock(width) for _ in range(n_blocks)])\n",
        "        self.exit  = nn.Conv2d(width, in_c*(scale**2), 3,1,1)\n",
        "        self.shuffle = nn.PixelShuffle(scale)\n",
        "    def forward(self, x):\n",
        "        up = F.interpolate(x, scale_factor=self.scale,\n",
        "                           mode='bilinear', align_corners=False)\n",
        "        x = self.entry(x)\n",
        "        x = self.body(x)\n",
        "        x = self.exit(x)\n",
        "        x = self.shuffle(x)\n",
        "        return up + x"
      ],
      "metadata": {
        "id": "4TCZr1XcCFWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = SRDataset(train_blur_dir, train_sharp_dir, transform)\n",
        "val_ds   = SRDataset(val_blur_dir,   val_sharp_dir,   transform)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    MultiScalePatchDataset(train_ds, patch_sizes=[128,256], out_size=256),\n",
        "    batch_size=16, shuffle=True,  num_workers=6, pin_memory=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    CenterPatchDataset(val_ds, patch_size=256),\n",
        "    batch_size=16, shuffle=False, num_workers=6, pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "7uJUym9LLQRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model, optimizer, scheduler, losses\n",
        "model = NAFNet(width=128, n_blocks=20).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
        "\n",
        "# OneCycleLR with true steps_per_epoch\n",
        "accum_steps = 4\n",
        "steps_epoch = math.ceil(len(train_loader) / accum_steps)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='max',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-6,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "\n",
        "# Losses\n",
        "l1_criterion = nn.L1Loss()\n",
        "vgg = vgg16(pretrained=True).features[:9].eval().to(device)\n",
        "for p in vgg.parameters(): p.requires_grad = False\n",
        "lpips_fn = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "scaler = GradScaler()\n",
        "best_psnr = 0.0\n",
        "patience, p_cnt = 5, 0"
      ],
      "metadata": {
        "id": "G45s3zbahHuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    pretrained_model_path = \"/content/best_nafnet_model.pth\" # Example path, change if needed\n",
        "    model.load_state_dict(torch.load(pretrained_model_path))\n",
        "    print(f\"Loaded pre-trained model from {pretrained_model_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Pre-trained model not found at {pretrained_model_path}. Starting training from scratch.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading pre-trained model: {e}. Starting training from scratch.\")"
      ],
      "metadata": {
        "id": "e_Ow3T6Mk6vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pct_start     = 0.3\n",
        "warmup_epochs = int(60 * pct_start)\n",
        "# Training loop\n",
        "for epoch in range(1, 61):\n",
        "    model.train()\n",
        "    stats = {'tot':0,'l1':0,'perc':0,'ssim':0,'pips':0}\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/60\", leave=False)\n",
        "    # Initialize postfix to an empty dictionary\n",
        "    pbar.postfix = {}\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for i, (lr, hr) in enumerate(pbar, 1):\n",
        "        lr, hr = lr.to(device), hr.to(device)\n",
        "        with autocast():\n",
        "            sr       = model(lr)\n",
        "            loss_l1  = l1_criterion(sr, hr)\n",
        "            loss_perc= F.l1_loss(vgg(sr), vgg(hr))\n",
        "            loss_ssim= 1 - ssim(sr, hr, data_range=1.0, size_average=True)\n",
        "            loss_pips= lpips_fn(denorm(sr), denorm(hr)).mean()\n",
        "            loss = (loss_l1 + 0.1*loss_perc + 0.5*loss_ssim + 0.01*loss_pips) / accum_steps\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        if i % accum_steps == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "            # scheduler.step()\n",
        "            curr_lr = optimizer.param_groups[0]['lr']\n",
        "            # Ensure pbar.postfix is a dictionary before unpacking\n",
        "            pbar.set_postfix(lr=f\"{curr_lr:.2e}\", **(pbar.postfix if isinstance(pbar.postfix, dict) else {}))\n",
        "\n",
        "        # accumulate stats\n",
        "        stats['tot']  += loss.item() * accum_steps\n",
        "        stats['l1']   += loss_l1.item()\n",
        "        stats['perc'] += loss_perc.item()\n",
        "        stats['ssim'] += loss_ssim.item()\n",
        "        stats['pips'] += loss_pips.item()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            lr_curr = optimizer.param_groups[0]['lr']\n",
        "            # Ensure pbar.postfix is a dictionary before unpacking\n",
        "            pbar.set_postfix({\n",
        "                'loss': f\"{stats['tot']/i:.4f}\",\n",
        "                'L1':   f\"{stats['l1']/i:.4f}\",\n",
        "                'Perc': f\"{stats['perc']/i:.4f}\",\n",
        "                'SSIM': f\"{stats['ssim']/i:.4f}\",\n",
        "                'PIPS': f\"{stats['pips']/i:.4f}\",\n",
        "                'lr':   f\"{lr_curr:.2e}\"\n",
        "            }, refresh=False) # Added refresh=False to prevent flickering\n",
        "\n",
        "    # Print the learning rate after the inner training loop finishes for the epoch\n",
        "    final_lr_epoch = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Epoch {epoch} finished. Final Learning Rate: {final_lr_epoch:.6f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_psnr = 0.0\n",
        "    with torch.no_grad():\n",
        "        for lr, hr in val_loader:\n",
        "            lr, hr = lr.to(device), hr.to(device)\n",
        "            sr = denorm(model(lr))\n",
        "            hr = denorm(hr)\n",
        "            mse = F.mse_loss(sr, hr, reduction='none')\n",
        "            mse = mse.view(mse.size(0), -1).mean(1)\n",
        "            val_psnr += (10 * torch.log10(1.0 / mse)).sum().item()\n",
        "    val_psnr /= len(val_loader.dataset)\n",
        "    print(f\"[Epoch {epoch}] Val PSNR: {val_psnr:.2f} dB\")\n",
        "\n",
        "    scheduler.step(val_psnr)\n",
        "\n",
        "    # Save best + Early stopping\n",
        "    if val_psnr > best_psnr:\n",
        "        best_psnr, p_cnt = val_psnr, 0\n",
        "        torch.save(model.state_dict(), \"best_nafnet_model.pth\")\n",
        "        print(\"→ Saved new best model.\")\n",
        "    else:\n",
        "        # Counting starts only after warm-up is complete\n",
        "        if epoch > warmup_epochs:\n",
        "            p_cnt += 1\n",
        "            if p_cnt >= patience:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n",
        "\n",
        "    # Sample inference & save\n",
        "    torch.cuda.empty_cache()\n",
        "    sample_lr, _ = val_ds[0]\n",
        "    sample_lr = sample_lr.unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        sample_sr = model(sample_lr)\n",
        "    save_image(denorm(sample_sr.cpu()), f\"sample_epoch{epoch}.png\")"
      ],
      "metadata": {
        "id": "PWta25KZklZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset for Evaluation\n",
        "class PairedTestDataset(Dataset):\n",
        "    def __init__(self, blur_dir, sharp_dir, transform=None):\n",
        "        blur_files  = [f for f in os.listdir(blur_dir)  if f.endswith('.png')]\n",
        "        blur_files.sort()\n",
        "        self.blur_paths  = [os.path.join(blur_dir, f) for f in blur_files]\n",
        "\n",
        "        sharp_files = [f for f in os.listdir(sharp_dir) if f.endswith('.png')]\n",
        "        sharp_files.sort()\n",
        "        self.sharp_paths = [os.path.join(sharp_dir, f) for f in sharp_files]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Use bilinear interpolation to keep consistent with training\n",
        "        lr = Image.open(self.blur_paths[idx]).convert(\"RGB\") \\\n",
        "               .resize((640, 360), Image.BILINEAR)\n",
        "        hr = Image.open(self.sharp_paths[idx]).convert(\"RGB\") \\\n",
        "               .resize((1280, 720), Image.BILINEAR)\n",
        "\n",
        "        if self.transform:\n",
        "            lr = self.transform(lr)\n",
        "            hr = self.transform(hr)\n",
        "\n",
        "        return lr, hr\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.blur_paths), len(self.sharp_paths))\n",
        "\n",
        "\n",
        "# Transforms & denorm\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485,0.456,0.406],\n",
        "        std=[0.229,0.224,0.225]\n",
        "    )\n",
        "])\n",
        "inv_transform = transforms.Normalize(\n",
        "    mean=[-m/s for m,s in zip([0.485,0.456,0.406],[0.229,0.224,0.225])],\n",
        "    std =[1/s for s in [0.229,0.224,0.225]]\n",
        ")\n",
        "def denorm(x):\n",
        "    return torch.clamp(inv_transform(x), 0.0, 1.0)\n",
        "\n",
        "\n",
        "# Paths\n",
        "blur_dir  = \"/content/datasets/content/datasets/test/blur_gamma\"\n",
        "sharp_dir = \"/content/datasets/content/datasets/test/sharp\"\n",
        "\n",
        "# DataLoader\n",
        "test_ds     = PairedTestDataset(blur_dir, sharp_dir, transform)\n",
        "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Load Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Corrected keyword argument from img_channel to in_c\n",
        "# Initialize NAFNet with the same parameters used during training\n",
        "model = NAFNet(in_c=3, width=128, n_blocks=20, scale=2).to(device) # Changed width and n_blocks\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/plot/best_enhanced_nafnet.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# LPIPS\n",
        "lpips_fn = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "# Import SSIM function\n",
        "!pip install scikit-image\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "# Metrics aggregation\n",
        "psnr_total, ssim_total, lpips_total = 0.0, 0.0, 0.0\n",
        "n = len(test_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (lr, hr) in enumerate(test_loader):\n",
        "        lr, hr = lr.to(device), hr.to(device)\n",
        "        sr = model(lr)\n",
        "\n",
        "        # Denormalize to [0,1]\n",
        "        sr_den = denorm(sr)\n",
        "        hr_den = denorm(hr)\n",
        "\n",
        "        # Vectorized PSNR calculation on GPU\n",
        "        mse = F.mse_loss(sr_den, hr_den, reduction='none')\n",
        "        mse = mse.view(mse.size(0), -1).mean(dim=1)\n",
        "        psnr_batch = 10 * torch.log10(1.0 / mse)\n",
        "        psnr_total += psnr_batch.item()\n",
        "\n",
        "        # SSIM\n",
        "        sr_img = sr_den[0].permute(1,2,0).cpu().numpy()\n",
        "        hr_img = hr_den[0].permute(1,2,0).cpu().numpy()\n",
        "        ssim_total += compare_ssim(hr_img, sr_img, data_range=1.0, channel_axis=2)\n",
        "\n",
        "        # LPIPS\n",
        "        lpips_score = lpips_fn(sr_den, hr_den)\n",
        "        lpips_total += lpips_score.item()\n",
        "\n",
        "        # Save every 400 photos\n",
        "        if i % 400 == 0:\n",
        "            save_image(lr.cpu(),     f\"sample_lr_{i}.png\", normalize=True)\n",
        "            save_image(sr_den.cpu(), f\"sample_sr_{i}.png\", normalize=True)\n",
        "            save_image(hr_den.cpu(), f\"sample_hr_{i}.png\", normalize=True)\n",
        "\n",
        "# Printing Results\n",
        "print(f\"\\nTest Results:\")\n",
        "print(f\" Avg PSNR:  {psnr_total / n:.2f} dB\")\n",
        "print(f\" Avg SSIM:  {ssim_total / n:.4f}\")\n",
        "print(f\" Avg LPIPS: {lpips_total / n:.4f}\")\n",
        "\n",
        "\n",
        "# Visualization function\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import pad\n",
        "\n",
        "def visualize_results(lr, sr, hr, idx=0):\n",
        "    to_pil = transforms.ToPILImage()\n",
        "    lr_img = to_pil(denorm(lr[idx].cpu()))\n",
        "    sr_img = to_pil(denorm(sr[idx].cpu()))\n",
        "    hr_img = to_pil(denorm(hr[idx].cpu()))\n",
        "\n",
        "    # pad LR to (1280,720)\n",
        "    lr_t = transforms.ToTensor()(lr_img)\n",
        "    _, h, w = lr_t.shape\n",
        "    pad_r = 1280 - w\n",
        "    pad_b = 720  - h\n",
        "    lr_pad = pad(lr_t, [0,0,pad_r,pad_b], fill=0)\n",
        "\n",
        "    grid = make_grid([lr_pad, transforms.ToTensor()(sr_img), transforms.ToTensor()(hr_img)], nrow=3)\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.imshow(grid.permute(1,2,0))\n",
        "    plt.axis('off')\n",
        "    plt.title('LR (padded) | SR | HR')\n",
        "    plt.savefig(\"visual_result.png\")\n",
        "    plt.show()\n",
        "\n",
        "# Call visualization\n",
        "lr_b, hr_b = next(iter(test_loader))\n",
        "sr_b = model(lr_b.to(device))\n",
        "if sr_b.shape[-2:] != hr_b.shape[-2:]:\n",
        "    sr_b = F.interpolate(sr_b, size=hr_b.shape[-2:], mode='bilinear', align_corners=False)\n",
        "visualize_results(lr_b, sr_b, hr_b)"
      ],
      "metadata": {
        "id": "rb3Hyx4mcUqC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}