{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "EIOMn1_Go9nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/realblur+gopro.zip\" -d \"/content/datasets\""
      ],
      "metadata": {
        "id": "Nbghz20UpAxl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "cpu_count = os.cpu_count()\n",
        "\n",
        "print(f\"Number of CPU cores: {cpu_count}\")"
      ],
      "metadata": {
        "id": "QJA3cX8hqjFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the latest PyTorch with CUDA 11.8 support\n",
        "!pip install torch torchvision torchaudio --upgrade --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "r0YjFQBIZ-rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image, ImageFilter\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "# Install the lpips library\n",
        "!pip install lpips\n",
        "import lpips\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.cuda.amp import GradScaler, autocast # Import for AMP\n",
        "from torchvision import models # Import for VGG16\n",
        "from tqdm import tqdm # Import for progress bar"
      ],
      "metadata": {
        "id": "bwjFUvocAupX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset for true SR+Enhancement task\n",
        "class SRDataset(Dataset):\n",
        "    def __init__(self, blur_dir, sharp_dir, transform=None):\n",
        "        self.lr_paths = sorted([os.path.join(blur_dir, f) for f in os.listdir(blur_dir) if f.endswith(('.png', '.jpg'))])\n",
        "        self.hr_paths = sorted([os.path.join(sharp_dir, f) for f in os.listdir(sharp_dir) if f.endswith(('.png', '.jpg'))])\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        lr = Image.open(self.lr_paths[idx]).convert(\"RGB\").resize((640, 360))   # low-res 模糊图\n",
        "        hr = Image.open(self.hr_paths[idx]).convert(\"RGB\").resize((1280, 720))  # GT 图\n",
        "\n",
        "        if self.transform:\n",
        "            lr = self.transform(lr)\n",
        "            hr = self.transform(hr)\n",
        "\n",
        "        return lr, hr\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.lr_paths), len(self.hr_paths))\n",
        "\n",
        "# Model\n",
        "class DnCNN_SR(nn.Module):\n",
        "    def __init__(self, scale=2, in_channels=3, features=64, num_layers=17):\n",
        "        super(DnCNN_SR, self).__init__()\n",
        "        layers = [nn.Conv2d(in_channels, features, kernel_size=3, padding=1), nn.ReLU(inplace=True)]\n",
        "        for _ in range(num_layers - 2):\n",
        "            layers.extend([nn.Conv2d(features, features, kernel_size=3, padding=1), nn.BatchNorm2d(features), nn.ReLU(inplace=True)])\n",
        "        layers.append(nn.Conv2d(features, in_channels * (scale ** 2), kernel_size=3, padding=1))\n",
        "        self.body = nn.Sequential(*layers)\n",
        "        self.upsample = nn.PixelShuffle(scale)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.upsample(self.body(x))\n",
        "\n",
        "# Transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std =[0.229,0.224,0.225])\n",
        "])\n",
        "inv_transform = transforms.Normalize(\n",
        "    mean=[-m/s for m,s in zip([0.485,0.456,0.406],[0.229,0.224,0.225])],\n",
        "    std =[1/s for s in [0.229,0.224,0.225]]\n",
        ")\n",
        "def denorm(x):\n",
        "    return torch.clamp(inv_transform(x), 0.0, 1.0)"
      ],
      "metadata": {
        "id": "i5S4X-8ILNCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DnCNN_SR with residual skip & PixelShuffle\n",
        "class DnCNN_SR(nn.Module):\n",
        "    def __init__(self, scale=2, in_channels=3, features=64, num_layers=17):\n",
        "        super().__init__()\n",
        "        layers = [nn.Conv2d(in_channels, features, 3, 1, 1),\n",
        "                  nn.ReLU(inplace=True)]\n",
        "        for _ in range(num_layers-2):\n",
        "            layers += [\n",
        "                nn.Conv2d(features, features, 3,1,1),\n",
        "                nn.BatchNorm2d(features),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ]\n",
        "        layers += [nn.Conv2d(features, in_channels*(scale**2), 3,1,1)]\n",
        "        self.body = nn.Sequential(*layers)\n",
        "        self.upsample = nn.PixelShuffle(scale)\n",
        "        self.scale = scale\n",
        "\n",
        "    def forward(self, x):\n",
        "        up = F.interpolate(x, scale_factor=self.scale,\n",
        "                           mode='bilinear', align_corners=False)\n",
        "        res = self.body(x)\n",
        "        res = self.upsample(res)\n",
        "        return up + res\n",
        "\n",
        "# Patch-wise wrapper\n",
        "class PatchWiseDataset(Dataset):\n",
        "    def __init__(self, ds, patch_size=128, scale=2): # Add scale parameter\n",
        "        self.ds = ds\n",
        "        self.ps = patch_size\n",
        "        self.scale = scale # Store the scale factor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        lr, hr = self.ds[idx]\n",
        "        _, h, w = lr.shape\n",
        "        # ensure that h-self.ps+1 and w-self.ps+1 are at least 1\n",
        "        if h-self.ps+1 <= 0 or w-self.ps+1 <= 0:\n",
        "            raise ValueError(f\"Patch size {self.ps} is too large for input image of size ({w}, {h}).\")\n",
        "\n",
        "        top  = torch.randint(0, h-self.ps+1, (1,)).item()\n",
        "        left = torch.randint(0, w-self.ps+1, (1,)).item()\n",
        "\n",
        "        lr_p = lr[:, top:top+self.ps, left:left+self.ps]\n",
        "        # Use self.scale for HR patch calculation\n",
        "        hr_p = hr[:, top*self.scale:top*self.scale+self.ps*self.scale,\n",
        "                  left*self.scale:left*self.scale+self.ps*self.scale]\n",
        "        return lr_p, hr_p"
      ],
      "metadata": {
        "id": "3i1qGQgKSc1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataloader setup\n",
        "train_blur = \"/content/datasets/content/datasets/train/blur_gamma\"\n",
        "train_sharp= \"/content/datasets/content/datasets/train/sharp\"\n",
        "val_blur   = \"/content/datasets/content/datasets/val/blur_gamma\"\n",
        "val_sharp  = \"/content/datasets/content/datasets/val/sharp\"\n",
        "\n",
        "train_ds = SRDataset(train_blur, train_sharp, transform)\n",
        "val_ds   = SRDataset(val_blur,   val_sharp,   transform)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    PatchWiseDataset(train_ds, patch_size=256, scale=2),\n",
        "    batch_size=64, shuffle=True, num_workers=6, pin_memory=True\n",
        ")\n",
        "val_loader   = DataLoader(\n",
        "    PatchWiseDataset(val_ds, patch_size=256, scale=2),\n",
        "    batch_size=64, shuffle=False, num_workers=6, pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "7uJUym9LLQRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# —— Model, optimizer, OneCycleLR, AMP ——\n",
        "device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model     = DnCNN_SR(scale=2, in_channels=3, features=64, num_layers=17).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=1e-3,\n",
        "    epochs=50,\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    pct_start=0.3,\n",
        "    div_factor=10,\n",
        "    final_div_factor=100\n",
        ")\n",
        "pixel_criterion = nn.L1Loss()\n",
        "scaler = GradScaler()\n",
        "\n",
        "# VGG perceptual loss\n",
        "vgg = models.vgg16(pretrained=True).features[:9].eval().to(device)\n",
        "for p in vgg.parameters(): p.requires_grad=False\n",
        "def perceptual_loss(sr, hr):\n",
        "    return F.l1_loss(vgg(sr), vgg(hr))"
      ],
      "metadata": {
        "id": "xRzvDWrZLS-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "best_psnr = 0.0; patience=5; p_cnt=0\n",
        "for epoch in range(1,51):\n",
        "    model.train()\n",
        "    stats = {'tot':0,'l1':0,'perc':0}\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/50\", leave=False)\n",
        "    for i,(lr,hr) in enumerate(pbar,1):\n",
        "        lr,hr = lr.to(device), hr.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        # Modified autocast call: remove device_type\n",
        "        with autocast(dtype=torch.float16):\n",
        "            sr = model(lr)\n",
        "            l1    = pixel_criterion(sr, hr)\n",
        "            perc = perceptual_loss(sr, hr)\n",
        "            loss = l1 + 0.1*perc\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        scheduler.step()\n",
        "\n",
        "        stats['tot']  += loss.item()\n",
        "        stats['l1']   += l1.item()\n",
        "        stats['perc'] += perc.item()\n",
        "        if i%10==0 or i==len(train_loader):\n",
        "            pbar.set_postfix({\n",
        "                'loss': f\"{stats['tot']/i:.4f}\",\n",
        "                'L1':   f\"{stats['l1']/i:.4f}\",\n",
        "                'Perc': f\"{stats['perc']/i:.4f}\",\n",
        "                'lr':   f\"{optimizer.param_groups[0]['lr']:.2e}\"\n",
        "            })\n",
        "\n",
        "    # Epoch summary\n",
        "    print(f\"[{epoch}] Train: loss={stats['tot']/len(train_loader):.4f}\"\n",
        "          f\" (L1={stats['l1']/len(train_loader):.4f},\"\n",
        "          f\" Perc={stats['perc']/len(train_loader):.4f})\")\n",
        "\n",
        "    # Validation on GPU PSNR\n",
        "    model.eval()\n",
        "    val_psnr = 0.0\n",
        "    with torch.no_grad():\n",
        "        for lr,hr in val_loader:\n",
        "            lr,hr = lr.to(device), hr.to(device)\n",
        "            # Ensure model output and HR are on the same device before denorm and metrics\n",
        "            sr = model(lr).to(device) # Ensure sr is on device\n",
        "            sr = denorm(sr)\n",
        "            hr = denorm(hr.to(device)) # Ensure hr is on device before denorm\n",
        "\n",
        "            # Metrics calculated on GPU\n",
        "            mse = F.mse_loss(sr, hr, reduction='none')\n",
        "            mse = mse.view(mse.size(0),-1).mean(1)\n",
        "            psnr_batch = 10*torch.log10(1.0/mse)\n",
        "            val_psnr += psnr_batch.sum().item()\n",
        "\n",
        "    val_psnr /= len(val_loader.dataset)\n",
        "    print(f\"[{epoch}] Val PSNR: {val_psnr:.2f} dB\")\n",
        "\n",
        "    # Early stopping & save\n",
        "    if val_psnr > best_psnr and val_psnr>20:\n",
        "        best_psnr = val_psnr; p_cnt=0\n",
        "        torch.save(model.state_dict(),\n",
        "                   \"/content/drive/MyDrive/plot/best_dncnn_sr.pth\")\n",
        "        print(\"→ Saved new best model\")\n",
        "    else:\n",
        "        p_cnt += 1\n",
        "        if p_cnt>=patience:\n",
        "            print(\"Early stopping.\")\n",
        "            break"
      ],
      "metadata": {
        "id": "sloNz8Gk0GOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset for Evaluation\n",
        "class PairedTestDataset(Dataset):\n",
        "    def __init__(self, blur_dir, sharp_dir, transform=None):\n",
        "        blur_files  = [f for f in os.listdir(blur_dir)  if f.endswith('.png')]\n",
        "        blur_files.sort()\n",
        "        self.blur_paths  = [os.path.join(blur_dir, f) for f in blur_files]\n",
        "\n",
        "        sharp_files = [f for f in os.listdir(sharp_dir) if f.endswith('.png')]\n",
        "        sharp_files.sort()\n",
        "        self.sharp_paths = [os.path.join(sharp_dir, f) for f in sharp_files]\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Use bilinear interpolation to keep consistent with training\n",
        "        lr = Image.open(self.blur_paths[idx]).convert(\"RGB\") \\\n",
        "               .resize((640, 360), Image.BILINEAR)\n",
        "        hr = Image.open(self.sharp_paths[idx]).convert(\"RGB\") \\\n",
        "               .resize((1280, 720), Image.BILINEAR)\n",
        "\n",
        "        if self.transform:\n",
        "            lr = self.transform(lr)\n",
        "            hr = self.transform(hr)\n",
        "\n",
        "        return lr, hr\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.blur_paths), len(self.sharp_paths))\n",
        "\n",
        "\n",
        "# Transforms & denorm\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485,0.456,0.406],\n",
        "        std=[0.229,0.224,0.225]\n",
        "    )\n",
        "])\n",
        "inv_transform = transforms.Normalize(\n",
        "    mean=[-m/s for m,s in zip([0.485,0.456,0.406],[0.229,0.224,0.225])],\n",
        "    std =[1/s for s in [0.229,0.224,0.225]]\n",
        ")\n",
        "def denorm(x):\n",
        "    return torch.clamp(inv_transform(x), 0.0, 1.0)\n",
        "\n",
        "# Paths\n",
        "blur_dir = \"/content/datasets/content/datasets/test/blur_gamma\"\n",
        "sharp_dir = \"/content/datasets/content/datasets/test/sharp\"\n",
        "\n",
        "# DataLoader\n",
        "test_ds     = PairedTestDataset(blur_dir, sharp_dir, transform)\n",
        "test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Load Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = DnCNN_SR().to(device)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/plot/best_dncnn_sr.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# LPIPS\n",
        "lpips_fn = lpips.LPIPS(net='alex').to(device)\n",
        "\n",
        "# Metrics aggregation\n",
        "psnr_total, ssim_total, lpips_total = 0.0, 0.0, 0.0\n",
        "n = len(test_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (lr, hr) in enumerate(test_loader):\n",
        "        lr, hr = lr.to(device), hr.to(device)\n",
        "        sr = model(lr)\n",
        "\n",
        "        # Denormalize to [0,1]\n",
        "        sr_den = denorm(sr)\n",
        "        hr_den = denorm(hr)\n",
        "\n",
        "        # Vectorized PSNR calculation on GPU\n",
        "        mse = F.mse_loss(sr_den, hr_den, reduction='none')\n",
        "        mse = mse.view(mse.size(0), -1).mean(dim=1)\n",
        "        psnr_batch = 10 * torch.log10(1.0 / mse)\n",
        "        psnr_total += psnr_batch.item()\n",
        "\n",
        "        # SSIM\n",
        "        sr_img = sr_den[0].permute(1,2,0).cpu().numpy()\n",
        "        hr_img = hr_den[0].permute(1,2,0).cpu().numpy()\n",
        "        ssim_total += compare_ssim(hr_img, sr_img, data_range=1.0, channel_axis=2)\n",
        "\n",
        "        # LPIPS\n",
        "        lpips_score = lpips_fn(sr_den, hr_den)\n",
        "        lpips_total += lpips_score.item()\n",
        "\n",
        "        # Save every 400 photos\n",
        "        if i % 400 == 0:\n",
        "            save_image(lr.cpu(),     f\"sample_lr_{i}.png\", normalize=True)\n",
        "            save_image(sr_den.cpu(), f\"sample_sr_{i}.png\", normalize=True)\n",
        "            save_image(hr_den.cpu(), f\"sample_hr_{i}.png\", normalize=True)\n",
        "\n",
        "# Printing Results\n",
        "print(f\"\\nTest Results:\")\n",
        "print(f\" Avg PSNR:  {psnr_total / n:.2f} dB\")\n",
        "print(f\" Avg SSIM:  {ssim_total / n:.4f}\")\n",
        "print(f\" Avg LPIPS: {lpips_total / n:.4f}\")\n",
        "\n",
        "\n",
        "# Visualization function\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import pad\n",
        "\n",
        "def visualize_results(lr, sr, hr, idx=0):\n",
        "    to_pil = transforms.ToPILImage()\n",
        "    lr_img = to_pil(denorm(lr[idx].cpu()))\n",
        "    sr_img = to_pil(denorm(sr[idx].cpu()))\n",
        "    hr_img = to_pil(denorm(hr[idx].cpu()))\n",
        "\n",
        "    # pad LR to (1280,720)\n",
        "    lr_t = transforms.ToTensor()(lr_img)\n",
        "    _, h, w = lr_t.shape\n",
        "    pad_r = 1280 - w\n",
        "    pad_b = 720  - h\n",
        "    lr_pad = pad(lr_t, [0,0,pad_r,pad_b], fill=0)\n",
        "\n",
        "    grid = make_grid([lr_pad, transforms.ToTensor()(sr_img), transforms.ToTensor()(hr_img)], nrow=3)\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.imshow(grid.permute(1,2,0))\n",
        "    plt.axis('off')\n",
        "    plt.title('LR (padded) | SR | HR')\n",
        "    plt.savefig(\"visual_result.png\")\n",
        "    plt.show()\n",
        "\n",
        "# Call visualization\n",
        "lr_b, hr_b = next(iter(test_loader))\n",
        "sr_b = model(lr_b.to(device))\n",
        "if sr_b.shape[-2:] != hr_b.shape[-2:]:\n",
        "    sr_b = F.interpolate(sr_b, size=hr_b.shape[-2:], mode='bilinear', align_corners=False)\n",
        "visualize_results(lr_b, sr_b, hr_b)\n"
      ],
      "metadata": {
        "id": "CLgSX4mzdZEH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}