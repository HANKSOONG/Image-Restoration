{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMhos4nLR/zV2Qz5zq8Obot",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HANKSOONG/image-repair-and-restoration-/blob/main/U_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n7uW4XGbKyJ3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/image_output.zip\" -d \"/content/datasets\""
      ],
      "metadata": {
        "id": "rrgrE0M-LNvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from PIL import Image\n",
        "\n",
        "class DeblurDataset(Dataset):\n",
        "    def __init__(self, denoised_dir, sharp_resized_dir, transform=None):\n",
        "        self.denoised_dir = denoised_dir\n",
        "        self.sharp_resized_dir = sharp_resized_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        self.filenames = os.listdir(denoised_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        filename = self.filenames[idx]\n",
        "\n",
        "        denoised_path = os.path.join(self.denoised_dir, filename)\n",
        "        sharp_resized_path = os.path.join(self.sharp_resized_dir, filename)\n",
        "\n",
        "        denoised_img = Image.open(denoised_path).convert('RGB')\n",
        "        sharp_resized_img = Image.open(sharp_resized_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            denoised_img = self.transform(denoised_img)\n",
        "            sharp_resized_img = self.transform(sharp_resized_img)\n",
        "\n",
        "        return denoised_img, sharp_resized_img, filename\n",
        "\n",
        "# Normalized\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Creat datasets\n",
        "dataset = DeblurDataset(denoised_dir='/content/datasets/denoised',\n",
        "              sharp_resized_dir='/content/datasets/sharp_resized',\n",
        "              transform=transform)\n",
        "\n",
        "# Split datasets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Definite dataloader\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=8)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=8)\n"
      ],
      "metadata": {
        "id": "IOVKyV-bOIwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n"
      ],
      "metadata": {
        "id": "Hkjtm8rFsGLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definite U-Net\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 512)\n",
        "        self.up1 = Up(1024, 256)\n",
        "        self.up2 = Up(512, 128)\n",
        "        self.up3 = Up(256, 64)\n",
        "        self.up4 = Up(128, 64)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n",
        "\n",
        "#Create U-Net model instance\n",
        "model = UNet(n_channels=3, n_classes=3)"
      ],
      "metadata": {
        "id": "0yGlrlCjneRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.models import mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
        "import torch.distributed as distance\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#def Perceptual Loss by MobileNet\n",
        "class PerceptualLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PerceptualLoss, self).__init__()\n",
        "        self.mobilenet = mobilenet_v3_small(weights=MobileNet_V3_Small_Weights.DEFAULT).features\n",
        "        self.mobilenet.eval()\n",
        "        for param in self.mobilenet.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        input_features = self.mobilenet(input)\n",
        "        target_features = self.mobilenet(target)\n",
        "        # Resize if necessary\n",
        "        if input_features.shape[2:] != target_features.shape[2:]:\n",
        "            input_features = F.interpolate(input_features, size=target_features.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        loss = nn.functional.mse_loss(input_features, target_features)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "S4c3mtNbn-Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "# Creat model and Adam optimizer\n",
        "debluring_model = UNet(n_channels=3, n_classes=3).to(device)\n",
        "mse_criterion = nn.MSELoss()\n",
        "perceptual_criterion = PerceptualLoss().to(device)\n",
        "optimizer = torch.optim.Adam(debluring_model.parameters(), lr=0.0001)\n",
        "\n",
        "# Initialize the ReduceLROnPlateau scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=3, verbose=True)"
      ],
      "metadata": {
        "id": "xr7AlQnAoIIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining Loss Function Weights\n",
        "mse_weight = 1.0\n",
        "perceptual_weight = 0.1"
      ],
      "metadata": {
        "id": "9JpGd1fEpGUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "def train_model(model, train_loader, val_loader, mse_criterion, perceptual_criterion, optimizer, num_epochs=100, early_stopping_tolerance=8):\n",
        "    best_val_loss = float('inf')\n",
        "    no_improvement_count = 0  # Early stopping counter\n",
        "\n",
        "    scaler = GradScaler()\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for denoised_img, sharp_resized_img in train_loader:\n",
        "            denoised_img = denoised_img.to(device)\n",
        "            sharp_resized_img = sharp_resized_img.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "           # Performing forward propagation using the autocast context\n",
        "            with autocast():\n",
        "                outputs = model(denoised_img)\n",
        "                mse_loss = mse_criterion(outputs, sharp_resized_img)\n",
        "                perceptual_loss = perceptual_criterion(outputs, sharp_resized_img)\n",
        "                total_loss = mse_weight * mse_loss + perceptual_weight * perceptual_loss\n",
        "\n",
        "            # Performing backward propagation and optimization using GradScaler\n",
        "            scaler.scale(total_loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += total_loss.item() * denoised_img.size(0)\n",
        "        train_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "        # Validation test\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for denoised_img, sharp_resized_img in val_loader:\n",
        "                denoised_img = denoised_img.to(device)\n",
        "                sharp_resized_img = sharp_resized_img.to(device)\n",
        "                outputs = model(denoised_img)\n",
        "                mse_loss = mse_criterion(outputs, sharp_resized_img)\n",
        "                perceptual_loss = perceptual_criterion(outputs, sharp_resized_img)\n",
        "                total_loss = mse_weight * mse_loss + perceptual_weight * perceptual_loss\n",
        "                val_loss += total_loss.item() * denoised_img.size(0)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "        # Early stopping check\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            no_improvement_count = 0\n",
        "        else:\n",
        "            no_improvement_count += 1\n",
        "            if no_improvement_count >= early_stopping_tolerance:\n",
        "                print(\"Stopping early due to no improvement in validation loss\")\n",
        "                break\n",
        "\n",
        "    return model\n",
        "\n",
        "train_model(debluring_model, train_loader, val_loader, mse_criterion, perceptual_criterion, optimizer, num_epochs=100, early_stopping_tolerance=8)"
      ],
      "metadata": {
        "id": "V3BQ0AKsoaBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "if torch.cuda.is_available() and torch.cuda.current_device() == 0:\n",
        "    model_path = '/content/drive/MyDrive/model/UNet/deblured_UNet.pth'\n",
        "    model_dir = os.path.expanduser(os.path.dirname(model_path))\n",
        "\n",
        "    if not os.path.exists(model_dir):\n",
        "        os.makedirs(model_dir)\n",
        "\n",
        "    torch.save(debluring_model.state_dict(), os.path.expanduser(model_path))\n",
        "    print(f\"Model saved to {model_path}.\")"
      ],
      "metadata": {
        "id": "wXgLbvKXqVZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse normalization transformation\n",
        "inv_normalize = transforms.Normalize(\n",
        "    mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
        "    std=[1/0.229, 1/0.224, 1/0.225]\n",
        ")"
      ],
      "metadata": {
        "id": "4eFoUKKCQvcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
        "from skimage.metrics import structural_similarity as compare_ssim\n",
        "from skimage import img_as_float\n",
        "import torch\n",
        "\n",
        "# Initialize the sum of PSNR and SSIM\n",
        "total_psnr_sharp = 0\n",
        "total_ssim_sharp = 0\n",
        "total_psnr_denoised = 0\n",
        "total_ssim_denoised = 0\n",
        "num_images = 0\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_path = '/content/drive/MyDrive/model/UNet/deblured_UNet4.pth'\n",
        "\n",
        "model = UNet(n_channels=3, n_classes=3)\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for denoised_img, sharp_resized_img in val_loader:\n",
        "      denoised_img = denoised_img.to(device)\n",
        "      sharp_resized_img = sharp_resized_img.to(device)\n",
        "\n",
        "      deblured_img = model(denoised_img)\n",
        "\n",
        "# Traverse the image to calculate PSNR and SSIM\n",
        "      for i in range(denoised_img.size(0)):\n",
        "        deblured = inv_normalize(deblured_img[i]).clamp(0, 1)\n",
        "        sharp = inv_normalize(sharp_resized_img[i]).clamp(0, 1)\n",
        "        denoised = inv_normalize(denoised_img[i]).clamp(0, 1)\n",
        "\n",
        "        deblured_np = deblured.cpu().numpy().transpose(1, 2, 0)\n",
        "        sharp_np = sharp.cpu().numpy().transpose(1, 2, 0)\n",
        "        denoised_np = denoised.cpu().numpy().transpose(1, 2, 0)\n",
        "\n",
        "    # Calculate PSNR and SSIM\n",
        "        psnr_sharp = compare_psnr(deblured_np, sharp_np)\n",
        "        ssim_sharp = compare_ssim(deblured_np, sharp_np, multichannel=True)\n",
        "        psnr_denoised = compare_psnr(deblured_np, denoised_np)\n",
        "        ssim_denoised = compare_ssim(deblured_np, denoised_np, multichannel=True)\n",
        "\n",
        "        total_psnr_sharp += psnr_sharp\n",
        "        total_ssim_sharp += ssim_sharp\n",
        "        total_psnr_denoised += psnr_denoised\n",
        "        total_ssim_denoised += ssim_denoised\n",
        "        num_images += 1\n",
        "\n",
        "# Calculate average PSNR and SSIM\n",
        "avg_psnr_sharp = total_psnr_sharp / num_images\n",
        "avg_ssim_sharp = total_ssim_sharp / num_images\n",
        "avg_psnr_denoised = total_psnr_denoised / num_images\n",
        "avg_ssim_denoised = total_ssim_denoised / num_images\n",
        "\n",
        "print(f'Average PSNR (Deblured vs Sharp): {avg_psnr_sharp}')\n",
        "print(f'Average SSIM (Deblured vs Sharp): {avg_ssim_sharp}')\n",
        "print(f'Average PSNR (Deblured vs Denoised): {avg_psnr_denoised}')\n",
        "print(f'Average SSIM (Deblured vs Denoised): {avg_ssim_denoised}')"
      ],
      "metadata": {
        "id": "wGYPxKpw7GHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model_path = '/content/drive/MyDrive/model/UNet/deblured_UNet4.pth'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNet(n_channels=3, n_classes=3)\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Definite dataloader\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=8)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=8)\n",
        "\n",
        "output_folder = '/content/drive/MyDrive/image_output/deblured2'\n",
        "\n",
        "def save_deblurred_images(data_loader, output_folder):\n",
        "    with torch.no_grad():\n",
        "        for denoised_img, sharp_resized_img, filename in data_loader:  # Updated to receive three items\n",
        "            denoised_img = denoised_img.to(device)\n",
        "            sharp_resized_img = sharp_resized_img.to(device)\n",
        "\n",
        "            deblured_img = model(denoised_img)\n",
        "\n",
        "            for i in range(denoised_img.size(0)):\n",
        "                deblured = inv_normalize(deblured_img[i]).clamp(0, 1)\n",
        "                deblured_np = deblured.cpu().numpy().transpose(1, 2, 0)\n",
        "\n",
        "                # Save deblurred image\n",
        "                plt.imsave(os.path.join(output_folder, filename[i]), deblured_np)\n",
        "\n",
        "\n",
        "# Process and save images for training and validation datasets\n",
        "save_deblurred_images(train_loader, output_folder)\n",
        "save_deblurred_images(val_loader, output_folder)\n"
      ],
      "metadata": {
        "id": "TY4kLZb4R3BO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}